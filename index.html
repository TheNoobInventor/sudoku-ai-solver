
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://TheNoobInventor.github.io/sudoku-ai-solver/index.html">
      
      
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.18">
    
    
      
        <title>Sudoku AI Solver</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.26e3688c.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#sudoku-ai-solver" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Sudoku AI Solver" class="md-header__button md-logo" aria-label="Sudoku AI Solver" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sudoku AI Solver
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Sudoku AI Solver
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/TheNoobInventor/sudoku-ai-solver" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    TheNoobInventor/sudoku-ai-solver
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  


  <li class="md-tabs__item">
    <a href="index.html" class="md-tabs__link md-tabs__link--active">
      Sudoku AI Solver
    </a>
  </li>

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Sudoku AI Solver" class="md-nav__button md-logo" aria-label="Sudoku AI Solver" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Sudoku AI Solver
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/TheNoobInventor/sudoku-ai-solver" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    TheNoobInventor/sudoku-ai-solver
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Sudoku AI Solver
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="index.html" class="md-nav__link md-nav__link--active">
        Sudoku AI Solver
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#sudoku" class="md-nav__link">
    Sudoku
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sudoku-ai-solver-steps" class="md-nav__link">
    Sudoku AI Solver Steps
  </a>
  
    <nav class="md-nav" aria-label="Sudoku AI Solver Steps">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load-input-image-and-extract-sudoku-puzzle" class="md-nav__link">
    Load input image and extract sudoku puzzle
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#localize-each-cell" class="md-nav__link">
    Localize each cell
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-learning-model-for-optical-character-recognition-ocr" class="md-nav__link">
    Deep Learning model for Optical Character Recognition (OCR)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solve-sudoku-puzzle" class="md-nav__link">
    Solve Sudoku puzzle
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#display-puzzle-solutions" class="md-nav__link">
    Display puzzle solutions
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#docker-container" class="md-nav__link">
    Docker Container
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#project-demonstration" class="md-nav__link">
    Project Demonstration
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#observations" class="md-nav__link">
    Observations
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recommendations" class="md-nav__link">
    Recommendations
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="sudoku-ai-solver">Sudoku AI Solver</h1>
<p>In this project, a Sudoku Artificial Intelligence (AI) puzzle solver is built using python, OpenCV, Deep Learning and Optical Character Recognition (OCR) methods to solve puzzles obtained from images. The steps required to implement the solver will be outlined after a brief overview of Sudoku puzzles.</p>
<h2 id="sudoku">Sudoku</h2>
<p>Sudoku is logic-based puzzle where the objective is to fill up a 9 x 9 grid with numbers from 1-9 in each row, each column and each mini 3 x 3 grid/block in a way that no number appears more than once in a row, column or mini grid. Each puzzle contains prefilled numbers with the empty cells/spaces to filled in with the Sudoku rules in mind. An example of a typical sudoku <a href="https://www.gmpuzzles.com/blog/category/sudoku/classic-sudoku/page/3/">puzzle</a> is shown below.</p>
<p align='center'>
    <img src='images/sudoku_sample.png' width=400>
</p>

<h2 id="sudoku-ai-solver-steps">Sudoku AI Solver Steps</h2>
<p>The steps needed to build the sudoku AI solver are outlined in the following flow chart (adapted from <a href="https://pyimagesearch.com/2020/08/10/opencv-sudoku-solver-and-ocr/">Pyimagesearch</a>).</p>
<p align='center'>
    <img src='images/sudoku_ai_steps.jpg' width=800>
</p>

<p>The sudoku AI solver starts out by accepting an input image containing a sudoku puzzle. Next, OpenCV is applied to locate and extract the sudoku board from the image. After this, each cell of the board is located then checked for digits in them. If there is a digit present, a Deep Learning model trained for Optical Character Recognition (OCR) is employed to identify it. At this point, given the cell locations and digits, a python script is run to solve the sudoku puzzle. Finally, the solved puzzle is displayed as an image to the user.</p>
<p>Most of these steps can be accomplished using OpenCV, however, training the OCR model involves using the Keras and Tensorflow libraries. The packages, libraries and frameworks used in this project are listed below:</p>
<ul>
<li><a href="https://opencv.org/">OpenCV</a> - Open source library that provides real-time computer vision tools, functions and hardware.</li>
<li><a href="https://jupyter.org/">JupyterLab</a> - Web-based interactive development environment for notebooks, code and data.</li>
<li><a href="https://www.tensorflow.org/">Tensorflow</a> - An Artificial Intelligence library that is used to build, train and deploy Machine Learning and Deep Learning models.</li>
<li><a href="https://keras.io/">Keras</a> - A Deep Learning library that provides an interface for Tensorflow.</li>
<li><a href="https://numpy.org/doc/stable/index.html">Numpy</a> - A Python library used for multidimensional array manipulation and calculations, basic linear algebra, statistical operations and more. It is utilized by OpenCV for array operations. </li>
<li><a href="https://matplotlib.org/">Matplotlib</a> - Library used for visualizations in Python.</li>
<li><a href="https://scikit-image.org/">Scikit-image</a> - Library used for image processing in Python.</li>
<li><a href="https://scikit-learn.org/stable/">Scikit-learn</a> - Library used for Machine Learning in Python.</li>
<li><a href="https://pypi.org/project/imutils/">Imutils</a> - Python package used for basic image processing operations.</li>
<li><a href="https://docs.pytest.org/en/7.1.x/">Pytest</a> - Python testing framework used to write tests for applications and libraries.</li>
</ul>
<p>Python is one of the main prerequisites for the project and can be downloaded from <a href="https://www.python.org/downloads/">here</a>. The python package manager, pip, is used to install the python packages in the list above -- pip can be installed from <a href="https://pip.pypa.io/en/stable/installation/">here</a>. Afterwards, the python packages are installed by executing this command in a terminal:</p>
<pre><code>pip install numpy matplotlib imutils jupyter jupyterlab scikit-image tensorflow pytest
</code></pre>
<p>Keras is automatically installed with Tensorflow. OpenCV is installed separately and can be downloaded <a href="https://docs.opencv.org/4.x/da/df6/tutorial_py_table_of_contents_setup.html">here</a> with options for Windows, Fedora and Ubuntu operating systems -- Ubuntu 20.04 is used for this project.</p>
<p>The <code>sudoku_puzzle_extractor.ipynb</code> Jupyter notebook in this repository is the main file used to build the sudoku AI solver which runs in JupyterLab. The file was based on the steps used in this <a href="https://pyimagesearch.com/2020/08/10/opencv-sudoku-solver-and-ocr/">Pyimagesearch article</a> with modifications to the functions in the Jupyter notebook, the OCR model, the script that solves the extracted puzzle and more. </p>
<p>A Docker container, based on a custom image built on Ubuntu 20.04, which mirrors the project repository with all the necessary packages, libraries and frameworks, can also be used to run the main Jupyter notebook to solve image extracted sudoku puzzles. The Docker build is detailed in a subsequent subsection.</p>
<p>Now that the project software environment has been setup, it is time to start building the sudoku AI solver.</p>
<h3 id="load-input-image-and-extract-sudoku-puzzle">Load input image and extract sudoku puzzle</h3>
<p>The input image is loaded into the <code>sudoku_puzzle_extractor.ipynb</code> notebook in the first line below:</p>
<pre><code>img = cv2.imread('sudoku_images/sudoku.jpg')
img = imutils.resize(img, width=600)
</code></pre>
<p align='center'>
    <img src='images/sudoku.jpg' width=400>
</p>

<p>In the second line, the image is resized to aid with image processing. The image needs to be processed before the puzzle can be extracted from it. The image is processed in the following steps and these are found in the <code>find_puzzle(img)</code> function in the notebook:</p>
<ul>
<li>
<p><strong>Convert the resized image to grayscale</strong></p>
<p>This is achieved using the following OpenCV function:</p>
<p><code>gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</code></p>
<p>This is a requirement for the other processing steps to work.</p>
</li>
<li>
<p><strong>Filter noise from the image</strong></p>
<p>The <a href="https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1">Gaussian Blur</a> is used to filter noise from the image. The general form of the <code>cv2.GaussianBlur()</code> function syntax is as follows:</p>
<p><p align='center'><big>GaussianBlur(src, dst, ksize, sigmaX, sigmaY)</big></p></p>
<p>Where,</p>
<ul>
<li><strong>src</strong> - Input image.</li>
<li><strong>dst</strong> - Output image of same size and type as src.</li>
<li><strong>ksize</strong> - Gaussian kernel size[height width ]. The kernel is a group of pixels that move along the src image pixel being worked on by the filter. Height and width must be odd numbers and can have different values. If ksize is set to [0,0], then ksize is computed from sigma value.</li>
<li><strong>sigmaX</strong> - Kernel standard derivation along X-axis (horizontal direction).</li>
<li><strong>sigmaY</strong> - Kernel standard derivation along Y-axis (vertical direction). If sigmaY = 0 then sigmaX value is taken for sigmaY.</li>
</ul>
<p>In the notebook, GaussianBlur is applied on the gray image with the following kernel size and sigmaX value:</p>
<p><code>blurred = cv2.GaussianBlur(gray, (7,7), 3)</code></p>
<p>More information on GaussianBlur and other OpenCV filtering and blurring techniques can be read about <a href="https://datacarpentry.org/image-processing/06-blurring/">here</a> and <a href="https://www.javatpoint.com/opencv-blur">here</a>.</p>
</li>
<li>
<p><strong>Image thresholding</strong></p>
<p>The next image processing step is <strong><em>thresholding</em></strong>. In attempting to find the puzzle from an image, being able to detect the edges and shapes within the image are important. Thresholding is a method of segmenting an image into different regions or contours. </p>
<p>A binary threshold is applied on the blurred grayscale image to convert it to consist of only two values, 0 or 255 - black or white respectively. The <code>cv2.adaptiveThreshold()</code> function was used to achieve this and it has the following <a href="(https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3)">general syntax</a>:
<br />  </p>
<p><p align='center'><big>adaptiveThreshold(src, dst, maxValue, adaptiveMethod, thresholdType, blockSize, C)</big></p></p>
<p>Where,</p>
<ul>
<li><strong>src</strong> - Input image.</li>
<li><strong>dst</strong> - Output image of same size and type as src.</li>
<li><strong>maxValue</strong> - Non-zero value assigned to the pixels for which the condition is satisifed.</li>
<li><strong>adaptiveMethod</strong> - Adaptive thresholding algorithm to use. There are two <a href="https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gaa42a3e6ef26247da787bf34030ed772c">adaptiveThreshold algorithms</a>: ADAPTIVE_THRESH_MEAN_C and ADAPTIVE_THRESH_GAUSSIAN_C.</li>
<li><strong>thresholdType</strong> - Thresholding type that must be either THRESHOLD_BINARY or THRESHOLD_BINARY_INV.</li>
<li><strong>blockSize</strong> - Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7 and so on.</li>
<li><strong>C</strong> - Constant subtracted from the mean or weighted mean. It is normally positive but may be zero or negative as well. </li>
</ul>
<p>The following command in the notebook applies an adaptiveThreshold to the blurred grascale image:</p>
<p><code>thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                cv2.THRESH_BINARY_INV, 11, 2)</code></p>
<p>Here the maxValue is set to 255, any pixel value in the image above 255 is set to 0, otherwise it is set to 255. This happens because the thresholdType is set to THRESHOLD_BINARY_INV, where INV stands for <em>inverse</em>. The thresholded image is shown below.</p>
<p><p align='center'>
    <img src='images/thresholded.jpg' width=400>
</p></p>
</li>
</ul>
<p>The next steps are to find the contours in the thresholded image and sort them in descending order to locate the outline of the sudoku puzzle. </p>
<p>As the name suggests, the <code>cv2.findContours()</code> function is used to retrieve the contours from the thresholded image and its use is shown in the code block below:</p>
<pre><code># Find contours in the thresholded image and sort them by size in descending order
cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
cnts = sorted(cnts, key=cv2.contourArea, reverse=True)
</code></pre>
<p>A copy of the thresholded image is passed into the function with the parameters: CHAIN_APPROX_SIMPLE, a contour approximation method which encodes a rectangular contuor with 4 points, and RETR_EXTERNAL, a contour retrieval method which retrieves only the extreme outer contours. Other options for contour approximation and retrieval modes are found <a href="https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#ga4303f45752694956374734a03c54d5ff">here</a> and <a href="https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#ga819779b9857cc2f8601e6526a3a5bc71">here</a> respectively. </p>
<p>The <code>imutils</code> package function, <code>grab_contours()</code>, returns the contours obtained in the previous line of code and these contours are then sorted by area in reverse/descending order. Two OpenCV functions, <code>cv2.arcLength()</code> and <code>cv2.approxPolyDP()</code>, are used to determine the puzzle outline. The applications of these functions are shown in the code blocks below:</p>
<pre><code># Initialize a contour that corresponds to the puzzle outline
puzzle_cnt = None

# Loop over the contours
for c in cnts:
    # Approximate the coutour
    peri = cv2.arcLength(c, True) 
    approx = cv2.approxPolyDP(c, 0.02 * peri, True)

    # If the approximated contour has 4 points, then it is assumed that 
    # this contour is the puzzle outline
    if len(approx) == 4:
        puzzle_cnt = approx
        break
</code></pre>
<p>Firstly, the puzzle outline variable, <code>puzzle_cnt</code>, is initialized. , the contours are looped over to find the perimeter of the contour with <code>cv2.arcLength()</code> while <code>cv2.approxPolyDP()</code> returns an approximated contour of the passed in contour. The figure <strong>0.02</strong> specifies the maximum variance between the original contour and the perimeter of the approximation, that is, the appromixation is 2% of the original contour. If the approximated contour has <strong>4</strong> points, it is assumed that this is the puzzle contour.</p>
<p>The obtained puzzle outline is drawn on the copy of the original image, using the <code>cv2.drawContours()</code> function, in the following lines of code:</p>
<pre><code>puzzle_outline = img.copy()
cv2.drawContours(puzzle_outline, [puzzle_cnt], -1, (0, 255, 0), 3)
</code></pre>
<p>The contour index is <strong>-1</strong> and a negative value indicates that all contours are drawn, <strong>(0, 255, 0)</strong> is the line color (green in this case) and <strong>3</strong> is the line thickness. More information on <code>cv2.drawContours()</code> is available <a href="https://docs.opencv.org/4.x/d6/d6e/group__imgproc__draw.html#ga746c0625f1781f1ffc9056259103edbc">here</a>.</p>
<p>The puzzle outline is shown in the image below.</p>
<p align='center'>
    <img src='images/puzzle_outline.jpg' width=400>
</p>

<p>Before moving on to locating and extracting digits in the puzzle, it is necessary to deskew the puzzle image, to a top-down bird's eye view to make it easier to determine rows, columns and cells of the sudoku puzzle. This operation is achieved by using the <code>four_point_transform()</code> function from the <code>imutils</code> package on both color and grayscale puzzle images:</p>
<pre><code>color_puzzle = four_point_transform(img, puzzle_cnt.reshape(4,2)) 
gray_puzzle = four_point_transform(gray, puzzle_cnt.reshape(4,2))  
</code></pre>
<p>The method <code>reshape(4,2)</code> reshapes the array of the puzzle contour to have a shape of <strong>(4, 2)</strong>, the required format for the <code>four_point_transform()</code> function. The image below shows the grayscale version after applying the transform. </p>
<p align='center'>
    <img src='images/extracted_gray.jpg' width=400>
</p>

<p>The <code>find_puzzle()</code> function returns the transformed images <code>color_puzzle</code> and <code>gray_puzzle</code> that will be used in subsequent steps in the sudoku AI solver as shown in this line of the main program cell in the notebook: </p>
<pre><code># Find puzzle in the image. Set debug to False to disable displaying image 
# processing steps.
color_puzzle, gray_puzzle = find_puzzle(img, debug=True)
</code></pre>
<p>The next step in the solver is to localize each cell in the puzzle.</p>
<h3 id="localize-each-cell">Localize each cell</h3>
<p>In order to localize each cell, the sudoku board needs to be initialized, split into individual cells and then generate the (x-y) coordinate location of each cell. The following lines in the main program cell achieve this:</p>
<pre><code># Initialize sudoku board
unsolved_board = np.zeros((9,9), dtype='int')

# Sudoku is a 9x9 grid (81 individual cells), location of each cell can be inferred by
# dividing the gray_puzzle image into a 9x9 grid
step_x = gray_puzzle.shape[1] // 9
step_y = gray_puzzle.shape[0] // 9

# Load model to detect digits
model = load_model('model_files/digit_classifier_model.h5')

# List of the (x-y) coordinate location of each cell
cell_locs = generate_cell_locations(step_x, step_y)
</code></pre>
<p>The OCR model is also loaded as it will be employed by the <code>classify_digit()</code> function called from the <code>generate_cell_locations()</code> function to classify digits; this process will be elaborated on later in this subsection. The steps of the <code>generate_cell_locations()</code> function are shown in the following code block:</p>
<pre><code># Initialize a list to store (x,y) coordinates of each cell location
cell_locs = []

# Loop over the grid lcoations
for y in range(9):
    # Initialize the current list of cell locations
    row = []

    for x in range(9):
        # Compute the starting and ending (x,y) coordinates of the current cell
        start_x = x * step_x
        start_y = y * step_y
        end_x = (x + 1) * step_x
        end_y = (y + 1) * step_y

        # Add the (x,y) coordinates to the cell locations list
        row.append((start_x, start_y, end_x, end_y))

        # Crop the cell from the gray_puzzle transformed image and then extract
        # the digit from the cell
        cell = gray_puzzle[start_y:end_y, start_x:end_x]
        digit = extract_digit(cell)

        # Confirm that the digit is not empty
        if digit is not None:
            classify_digit(digit, x, y)

    # Add the row to the cell locations
    cell_locs.append(row)

return cell_locs
</code></pre>
<p>The function starts by initializing a list, <code>cell_locs</code>, to store the (x, y) coordinates of each cell location. It then iterates over each grid location of the sudoku board, row by row, and appends the <code>start_x, start_y, end_x, end_y</code> values of each cell in a list. </p>
<p>The figure below illustrates a typical cell with the start and end (x, y) coordinates.</p>
<p align='center'>
    <img src='images/sudoku_cell.jpg' width=400>
</p>

<p>For each iteration, the <code>generate_cell_locations()</code> function calls the <code>extract_digit()</code> function to determine if there is a digit present in the current cell. This process of digit extraction is shown in the code block below:</p>
<pre><code># Apply automatic thresholding to the cell and then clear any connected borders 
# that touch the border of the cell
thresh = cv2.threshold(cell, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
thresh = clear_border(thresh)

# Find contours in the thresholded cell
cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)

# If no contours were found then this is an empty cell
if len(cnts)==0:
    return None

# Otherwise find the largest contour in the cell and create a mask for 
# the contour
c = max(cnts, key=cv2.contourArea)
mask = np.zeros(thresh.shape, dtype=&quot;uint8&quot;)
cv2.drawContours(mask, [c], -1, 255, -1)

# Compute the perecentage of masked pixels relative to the total area of the image
(h, w) = thresh.shape
percent_filled = cv2.countNonZero(mask) / float(w * h)

# If less than 3% of the mask is filled then we are looking at noise and 
# can safely ignore the contour
if percent_filled &lt; 0.03:
    return None

# Apply the mask to the thresholded cell
digit = cv2.bitwise_and(thresh, thresh, mask=mask) 

return digit
</code></pre>
<p>Similar to finding the outline of the sudoku puzzle, thresholding techniques are also applied here in extracting the digit. The function <code>clear_border()</code>, from the <code>skimage.segmentation</code> library, is used to clear any connected borders touching a respective cell border. The next step is to find contours in the thresholded cell, if no contours are found, <code>None</code> is returned. If there are contours present in <code>cnts</code>, the largest contour by pixel area is found and a mask is created for it. </p>
<p>Dividing the pixel area of the mask by the area of the cell itself gives the <code>percentFilled</code> value, that is, how much the cell is "filled up" with white pixels. This percentage is used to confirm if the contour is noisy or if contains a digit; any percentage less than 3% is assumed to contain only noise. </p>
<p>If the cell is not noisy, the mask is applied to the thresholded image and the digit is returned. As an example, the extracted cell of the bottom left hand corner from the puzzle <code>sudoku.jpg</code> is shown below.</p>
<p align='center'>
    <img src='images/digit.jpg' width=200>
</p>

<p>The returned digit is then classified using the <code>classify_digit()</code> function with the steps shown in the following code block:</p>
<pre><code># Resize the digit to 28x28 pixels and prepare it classification. 
# 28x28 is the size of images in the MNIST dataset
roi = cv2.resize(digit, (28, 28))
roi = roi.astype(&quot;float&quot;)/255.0
roi = img_to_array(roi)
roi = np.expand_dims(roi, axis=0)

# Classify the digit and update the sudoku board with the prediction
pred = model.predict(roi, verbose=0).argmax(axis=1)[0]
unsolved_board[y, x] = pred
</code></pre>
<p>The digit, <code>roi</code>, is resized to 28x28 pixels -- the size of the images in the MNIST dataset used to train deep learning models for optical character recognition. The <code>roi</code> digit is preprocessed before the <code>predict()</code> method is called on the <code>model</code> to predict the digit. The sudoku board is then updated with this prediction, thus replacing the default value of 0.</p>
<p>The current row of the board is appended to <code>cell_locs</code> list and this process continues until all the rows of the sudoku board have been worked on. </p>
<p>The following subsection briefly explains the process involved in building the deep learning model used by the <code>classify_digit()</code> function for OCR.</p>
<h3 id="deep-learning-model-for-optical-character-recognition-ocr">Deep Learning model for Optical Character Recognition (OCR)</h3>
<p>Deep learning is a subset of Machine Learning (itself a subset of Artificial Intelligence) techniques that use artificial neural network architectures to learn from data. <a href="https://www.ibm.com/cloud/learn/deep-learning">Neural networks</a> are layers of nodes, similar to the neurons in the human brain, that attempt to simulate the brain's ability to learn from large amounts of data and make predictions. The nodes within individual layers are connected to <a href="https://www.simplilearn.com/tutorials/deep-learning-tutorial/what-is-deep-learning">adjacent ones</a>. The network is said to be <em>'deep'</em> depending on the number of hidden layers it has. Traditional <a href="https://www.mathworks.com/discovery/deep-learning.html">neural networks</a> only contain 2-3 hidden layers, while deep networks can have as many as 150. </p>
<p>The <a href="https://www.mathworks.com/discovery/deep-learning.html">figure</a> below shows the layout of a typical neural network. </p>
<p align='center'>
    <img src='images/neural_network.jpg' width=600>
</p>

<p>Deep learning models are trained using a large set of labeled data and neural network architectures that learn features directly from the data without the need for manual feature extraction. Convolutional neural network (CNN or ConvNet) is one of the most popular types of deep neural networks. A CNN convolves learned features with input data, and uses 2D convolutional layers, making this architecture well suited to processing 2D data, such as images.</p>
<p>The CNN works by extracting features directly from images. The relevant features are not pretrained; they are learned while the network trains on a collection of images. This automated feature extraction makes deep learning models highly accurate for computer vision tasks such as object classification. The <a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">figure</a> below illustrates the CNN process for classifying handwritten digits. </p>
<p align='center'>
    <img src='images/convnet.jpeg' width=600>
</p>

<p>More information about convolutional neural networks can be found <a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">here</a> and <a href="https://www.simplilearn.com/tutorials/deep-learning-tutorial/convolutional-neural-network">here</a>. </p>
<p>To perform optical character recognition on the digits obtained from the <code>extract_digit()</code>, a convolutional neural model is built and trained using the <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a>. The MNIST dataset is a classic dataset that contains 28x28 pixels sized images of handwritten digits, with 60,000 images for model training and 10,000 images for model testing. The handwritten images are grayscale single digits from 0 to 9. A sample of these images is shown <a href="https://en.wikipedia.org/wiki/MNIST_database">below</a>.</p>
<p align='center'>
    <img src='images/MnistExamples.png' width=500>
</p>

<p>The MNIST dataset is part of the Keras deep learning library so it only needs to be loaded to the <code>train_digit_classifier.ipynb</code> notebook, in the <code>model_files</code> directory, used to build and train the OCR deep learning model.</p>
<p>To build the deep learning model, the following packages need to be imported into the <code>train_digit_classifier.ipynb</code> notebook:</p>
<pre><code>import numpy as np
import matplotlib.pyplot as plt
from keras.datasets import mnist
from keras.utils.np_utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Activation
from sklearn.metrics import classification_report
</code></pre>
<p>Next, the MNIST dataset is loaded and split into training and test data and labels.</p>
<pre><code>(train_data, train_labels), (test_data, test_labels) = mnist.load_data()
</code></pre>
<p>After loading the dataset, the data needs to be preprocessed before using it to build the model. One of these processes is to one hot encode the test and train data labels. The original labels of the images are given as a list of numbers: <code>[4,5,7,...,0,9,1]</code>. These need to be converted to one-hot encoding.</p>
<p>In one-hot encoding, the label of an image is based off the index position in the label array. For instance, a drawn digit of 4 would have the label array:</p>
<p>-<code>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</code></p>
<p>Or the integer 9 would be encoded as:</p>
<p>-<code>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</code></p>
<p>Without one-hot encoding, the neural network might think there could be values between numbers in a list instead of distinct categories or labels. One-hot encoding is easily done in Keras with the utility function, <code>to_categorical()</code> which accepts data and the number of classes (0 - 9) as arguments. </p>
<pre><code>test_labels = to_categorical(test_labels, 10)
train_labels = to_categorical(train_labels, 10)
</code></pre>
<p>The next preprocess step is to normalize the test and train data to range [0, 1].</p>
<pre><code>train_data = train_data / 255
test_data = test_data / 255
</code></pre>
<p>The final step before building is the model is to reshape the test and train data to include color channels. Only one channel is included here for grayscale.</p>
<pre><code>train_data = train_data.reshape(train_data.shape[0], 28, 28, 1)
test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)
</code></pre>
<p>With the data preprocessed, it is time to build the model. The paramters used to build the following CNN model were obtained from <a href="https://becominghuman.ai/part-3-solving-the-sudoku-ai-solver-13f64a090922">here</a>.</p>
<pre><code># Create model
model = Sequential()

# First set of Convolution layer
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', 
input_shape=(28, 28, 1)))

# Pooling layer
model.add(MaxPool2D((2, 2)))

# Second set of Convolution layer
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))

# Third set of Convolution layer
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))

# Pooling layer
model.add(MaxPool2D((2, 2)))

# Flat layer: 2 Dimension --&gt; 1 Dimension
model.add(Flatten())
model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))

# Output layer/classifer
model.add(Dense(10, activation='softmax'))

# Compile model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>
<p>The summary of the built model is shown below.</p>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 26, 26, 32)        320       

 max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         
 )                                                               

 conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     

 conv2d_2 (Conv2D)           (None, 9, 9, 64)          36928     

 max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         
 2D)                                                             

 flatten (Flatten)           (None, 1024)              0         

 dense (Dense)               (None, 100)               102500    

 dense_1 (Dense)             (None, 10)                1010      

=================================================================
Total params: 159,254
Trainable params: 159,254
Non-trainable params: 0
</code></pre>
<p>The model is trained using the <code>fit()</code> function below. An epoch is the number of times the network goes through the training set. </p>
<pre><code>model.fit(train_data, train_labels, epochs=20)
</code></pre>
<p>The following is an excerpt from the model training output.</p>
<pre><code>Epoch 1/20
1875/1875 [==============================] - 34s 18ms/step - loss: 0.1174 - accuracy: 0.9637
Epoch 2/20
1875/1875 [==============================] - 34s 18ms/step - loss: 0.0414 - accuracy: 0.9876
Epoch 3/20
1875/1875 [==============================] - 35s 19ms/step - loss: 0.0300 - accuracy: 0.9907
Epoch 4/20
1875/1875 [==============================] - 35s 19ms/step - loss: 0.0208 - accuracy: 0.9934
Epoch 5/20
1875/1875 [==============================] - 34s 18ms/step - loss: 0.0164 - accuracy: 0.9949
Epoch 6/20
1625/1875 [=========================&gt;....] - ETA: 4s - loss: 0.0116 - accuracy: 0.9965
---
Epoch 17/20
1875/1875 [==============================] - 33s 17ms/step - loss: 0.0051 - accuracy: 0.9983
Epoch 18/20
1875/1875 [==============================] - 33s 17ms/step - loss: 0.0048 - accuracy: 0.9984
Epoch 19/20
1875/1875 [==============================] - 33s 17ms/step - loss: 0.0050 - accuracy: 0.9986
Epoch 20/20
1875/1875 [==============================] - 33s 18ms/step - loss: 0.0049 - accuracy: 0.9987
</code></pre>
<p>The next action to be carried is to predict classes on the test images; images that the model is yet to see.</p>
<pre><code>predictions = model.predict(test_data)
</code></pre>
<p>The correct answers, <code>test_labels</code>, are compared with the generated predictions using the <code>classification_report()</code> function from the <code>sklearn.metrics</code> package.</p>
<pre><code>print(classification_report(test_labels.argmax(axis=1), predictions.argmax(axis=1)))
</code></pre>
<p>The report output is shown below and it can be observed that the accuracy, precision, recall and f1-score are all 99%.</p>
<pre><code>              precision    recall  f1-score   support

           0       0.99      0.99      0.99       980
           1       1.00      0.99      1.00      1135
           2       0.98      1.00      0.99      1032
           3       1.00      0.99      0.99      1010
           4       0.99      0.99      0.99       982
           5       0.98      0.99      0.99       892
           6       0.99      0.99      0.99       958
           7       0.99      0.99      0.99      1028
           8       1.00      0.98      0.99       974
           9       0.99      0.98      0.98      1009

    accuracy                           0.99     10000
   macro avg       0.99      0.99      0.99     10000
weighted avg       0.99      0.99      0.99     10000
</code></pre>
<p>The trained model can be saved by running the following command in the notebook.</p>
<pre><code>model.save('model_name.h5')
</code></pre>
<p>This project already has a trained model, <code>digit_classifier_model.h5</code>, present in the <code>model_files</code> directory, used to OCR the extracted digit. </p>
<p>At this stage of the sudoku AI solver, the trained model has classified the extracted digits from the previous and substituted them in the respective cells of <code>unsolved_board</code>. The next step is to use the <code>solve_sudoku.py</code> Python script to solve the <code>unsolved_board</code> sudoku puzzle.</p>
<h3 id="solve-sudoku-puzzle">Solve Sudoku puzzle</h3>
<p>Going back the main program cell in the <code>sudoku_puzzle_extractor.ipynb</code> notebook, the <code>unsolved_board</code> puzzle is converted to a list data type prior to making any solving attempts. This conversion is necessary as the <code>solve_sudoku.py</code> script was written to solve a sudoku puzzle in a list format and not a numpy array.</p>
<pre><code>unsolved_board = unsolved_board.tolist()
</code></pre>
<p>Finally a deep copy of the <code>unsolved_board</code> puzzle list is made before passing it into the <code>solve_puzzle()</code> function from the <code>solve_sudoku.py</code> script. This is done to enable the sudoku puzzle solutions to be overlayed (using the <code>display_solutions()</code> function discussed in the next subsection) on the puzzle image while avoiding cells with numbers already present.</p>
<pre><code>unsolved_board_copy = copy.deepcopy(unsolved_board) 

# Solve puzzle
solved_board = solve_puzzle(unsolved_board_copy, debug=False)
</code></pre>
<p>To solve the sudoku puzzle, <em><strong>recursion</strong></em> and <em><strong>backtracking</strong></em> are used. Recursion involves a function calling itself until a base case is reached. For example, to compute the factorial of 5, a function like the one below can be used:</p>
<pre><code>def factorial(x):
    if x ==  0: # Base case
        return 1
    return x * factorial(x - 1)
</code></pre>
<p>Calling <code>factorial(5)</code> results to the number 120. The steps of recursively arriving at this output are shown below:</p>
<pre><code>factorial(5) =  5 x factorial(4)
                5 x 4 x factorial(3)
                5 x 4 x 3 x factorial(2)    
                5 x 4 x 3 x 2 x factorial(1)
                5 x 4 x 3 x 2 x 1 x factorial(0)
                5 x 4 x 3 x 2 x 1 x 1 = 120
</code></pre>
<p>The base case, <code>factorial(0) = 1</code>, is the terminating condition to ensure that the function does not keep recursively calling itself until the program crashes; due to the limit to the number of recursive calls that can be made.</p>
<p>Backtracking is an algorithmic technique for solving constraint-satisfaction problems  recursively without trying all possibilities. Some algorithms that employ <a href="https://cs.lmu.edu/~ray/notes/backtracking/">backtracking</a> include:</p>
<ul>
<li>N-Queens problem in chess,</li>
<li>Traveling salesperson problem,</li>
<li>Graph coloring problem, and </li>
<li>Sudoku.</li>
</ul>
<p>In the case of solving sudoku puzzles, valid guesses to solve the puzzle are constrained by the rules of the game. For a number to be part of a valid set of guesses (recall that guesses can only be from 1 to 9) to fill up an empty cell on the board, the number should <strong>not</strong>:</p>
<ul>
<li>already be present in the associated row of the empty cell,</li>
<li>already be present in the associated column of the empty cell, and</li>
<li>already be present in the associated 3x3 block of the empty cell.</li>
</ul>
<p>To solve a sudoku puzzle using backtracking, start out with the first empty cell on the board, and the first number from a set of valid guesses is chosen to fill up the cell. The next empty cell is worked on and the first number from the a valid set of guesses is chosen to fill out the cell. If an empty cell is reached that does not have any valid guesses, the solver backtracks to the previous cell and chooses the next guess in the set of valid guesses and tries moving forward. This process continues until the puzzle is solved. </p>
<p>A sample of this <a href="(https://en.wikipedia.org/wiki/Sudoku)">sudoku</a> solving backtracking process is shown in the diagram below.</p>
<p align='center'>
    <img src='images/backtracking.jpg' width=800>
</p>

<p>The <code>solve_puzzle()</code> function, from the <code>solve_sudoku.py</code> script, is the function that attempts to solve the <code>unsolved_board_copy</code> puzzle. The <code>solve_puzzle()</code> code block is shown below:</p>
<pre><code># If debug is set to True, check if puzzle is valid
if debug:
    if not is_puzzle_valid(puzzle):
        return False

# Find the next empty space of the puzzle to guess in
row, col = find_next_empty(puzzle)

# If find_next_empty() returns None, None that means there is no free space/element left in the
# puzzle. Since only valid guesses are filled in (using is_guess_valid() function), the puzzle has been solved.
if row is None:
    return puzzle

# If there is a space in the puzzle, pick a number from 1 - 9
for guess in range(1, 10): 

    # Check if guess is valid
    if is_guess_valid(puzzle, guess, row, col):

        # Place valid guess in the current empty space of the puzzle
        puzzle[row][col] = guess

        # Recursively call the solve_puzzle() function. Returning True means that the puzzle is solved, 
        # from row/column having a value of None.
        if solve_puzzle(puzzle):
            return puzzle

    # If the current guess is not valid, then backtrack and try a different number
    puzzle[row][col] = 0

# If none of the guesses work, this current iteration of the recursive function is closed and 
# operation is moved up the previous level. If at the end, none of the numbers tried works, the puzzle
# is declared unsolvable.
return False
</code></pre>
<p>The function starts out by checking if the debug flag is set to <code>True</code>. This feature was added to confirm if the puzzle, prior to any solving attempts, is valid; not having any duplicates in a row, column or 3x3 puzzle block. The puzzle validity check slows the performance of the function, thus the flag is set to <code>False</code> by default. The flag is only set to <code>True</code> to unit test the script with Pytest, discussed afterwards, and to troubleshoot errors encountered in solving the puzzle.</p>
<p>The next step is to find the next empty space/cell in the puzzle to guess in. With an empty cell, guesses to fill up the cell are checked for validity using the constraints enumerated earlier. Once the first valid guess is found, it is inputted into the empty cell. After this, <code>solve_puzzle()</code> recursively calls itself and the whole process of picking guesses to fill up empty cells, as explained earlier with the aid of the diagram, is repeated until the puzzle is solved. If there are no more empty cells, the puzzle has been solved and is returned to the <code>solved_board</code> variable.</p>
<p>The utility functions used by the <code>solve_puzzle()</code> function are well documented and can be viewed in the <code>solve_sudoku.py</code> script. Credit for the base sudoku solver is attributed to <a href="https://www.youtube.com/watch?v=tvP_FZ-D9Ng">Kylie Ying</a>.</p>
<p><strong>Side note about Unit Testing</strong></p>
<p>Before advancing to the final step of the sudoku AI solver, the unit tests for the sudoku solver script will be considered. The test script, <code>test_solve_sudoku.py</code>, was written to test edge cases and catch exceptions that the <code>solve_sudoku.py</code> might encounter. The test script initializes the following puzzle lists: <code>puzzle_1</code>, <code>solution_1</code>, <code>puzzle_2</code>, <code>puzzle_3</code>, and <code>puzzle_4</code>. Where <code>puzzle_1</code> is a puzzle to be solved and <code>solution_1</code> is its solution. The lists <code>puzzle_2</code>, <code>puzzle_3</code> and <code>puzzle_4</code> are invalid puzzles that need to have their resultant exceptions caught.</p>
<p>The unit tests carried out on the sudoku solver:</p>
<ul>
<li>
<p>Test to confirm that the puzzle and solution are not the same before invoking the solve_puzzle() method,</p>
</li>
<li>
<p>Test to confirm that the puzzle has an element that is not of type <code>int</code>,</p>
</li>
<li>
<p>Test to confirm that the solved puzzle and the provide solution are the same,</p>
</li>
<li>
<p>Test to confirm that there is a duplicate in a puzzle row, and</p>
</li>
<li>
<p>Test to confirm that there is a duplicate in a puzzle block.</p>
</li>
</ul>
<p>The following command runs the unit tests using Pytest:</p>
<pre><code>pytest test_solve_sudoku.py
</code></pre>
<p>This command can also be run in the Docker container (to be discussed in a subsequent subsection) of this project.</p>
<h3 id="display-puzzle-solutions">Display puzzle solutions</h3>
<p>Assuming that there are no errors encountered when attempting to solve the sudoku puzzle, the solved puzzle is returned to the <code>solved_board</code> variable and the solutions are displayed on the extracted color puzzle image using the function, <code>display_solutions(cell_locs, color_puzzle)</code>. This is expressed in the following lines from the main Jupyter notebook:</p>
<pre><code>if not solved_board:
    print('\nPuzzle could not be solved, check training model.\n')
else:
    display_solutions(cell_locs, color_puzzle)
</code></pre>
<p>The solver script returns <code>False</code> if an error occurs, otherwise the returned solved puzzle equates to <code>True</code>. The code block for the <code>display_solutions()</code> function is shown below.</p>
<pre><code># Loop over the cell locations and boards
for (cell_row, unsolved_board_row, solved_board_row) in zip(cell_locs, unsolved_board, solved_board):

    # Loop over individual cells in the row
    for (box, unsolved_digit, solved_digit) in zip(cell_row, unsolved_board_row, solved_board_row):
        if unsolved_digit == 0:
            # Unpack the cell coordinates
            start_x, start_y, end_x, end_y = box

            # Compute the coordinates of where the digit will be drawn 
            # on the output puzzle image
            text_x = int((end_x - start_x) * 0.33)
            text_y = int((end_y - start_y) * -0.2)
            text_x += start_x
            text_y += end_y

            # Draw the digit on the sudoku puzzle image
            cv2.putText(
                color_puzzle, str(solved_digit), (text_x, text_y), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)

display_img(color_puzzle, 'Solved Puzzle')
</code></pre>
<p>The function loops over the individual cells of the <code>unsolved_board</code> and <code>solved_board</code> lists. It then checks for digits in the <code>unsolved_board</code> with a value of 0, and the solution of the corresponding cell in the <code>solved_board</code> is drawn onto the respective location in the <code>color_puzzle</code> image. This procedure continues until the image is filled up with the puzzle solutions and the resultant image is outputted to the Jupyter notebook. The solved sudoku puzzle for <code>sudoku.jpg</code> is shown in the image below.</p>
<p align='center'>
    <img src='images/solved_puzzle.jpg' width=400>
</p>

<p>Now the sudoku AI solver is complete.</p>
<h2 id="docker-container">Docker Container</h2>
<p>The main Jupyter notebook and relevant files needed for this project can be run in a Docker container. </p>
<p>First pull the image (with a compressed size of 1.93 GB) from the Docker Hub repository:</p>
<pre><code>docker pull thenoobinventor/sudoku-ai-solver:latest
</code></pre>
<p>Then run a container (choose a name for it) based on the image:</p>
<pre><code>docker run -it --rm -p 8890:8890 --name container_name thenoobinventor/sudoku-ai-solver:latest
</code></pre>
<p>The Docker image can also be built directly from the <code>Dockerfile</code>. 
The <code>requirements.txt</code> file, in the project repository, contains the list of packages  needed for the project and are installed during the image build process.  </p>
<p>To build the image, open a terminal window, navigate to the directory with the <code>Dockerfile</code> and run the following command (replacing the default name and tag for the image):</p>
<pre><code>docker build --load -t name:tag .
</code></pre>
<h2 id="project-demonstration">Project Demonstration</h2>
<p>The video below walks through running the Jupyter notebook sudoku AI solver in a Docker container.</p>
<p><a href="https://youtu.be/_Kjz8v-J1Os"><img src="images/thumbnail.png" width="50%"></a></p>
<h2 id="observations">Observations</h2>
<p>The main observation while working on this project involved the deep learning model used for classifying the digits. It took several iterations of model parameters to obtain a model that successfully extracts and classifies the digits of the sudoku images used in this project. Despite this, the model had some issues correctly identifying all the digits of other puzzle images. The quality of the images used and the model parameters are the main factors to not achieving the desired classifications and that should be considered when using the model on other puzzle images. Therefore, further adjustments to some of the model parameters -- number of epochs, number of layers, number of filters, kernel size, pool size -- should be made to correctly train the model.</p>
<h2 id="recommendations">Recommendations</h2>
<p>A suggestion to improve on this project is to add functionality to use a webcam to overlay the puzzle solutions in a video stream of the puzzle. </p>
<h2 id="references">References</h2>
<ul>
<li>
<p><a href="https://aakashjhawar.medium.com/sudoku-solver-using-opencv-and-dl-part-1-490f08701179">Sudoku Solver using Computer Vision &amp; Deep Learning</a></p>
</li>
<li>
<p><a href="https://becominghuman.ai/image-processing-sudokuai-opencv-45380715a629">Image Processing Sudoku AI</a></p>
</li>
<li>
<p><a href="https://pyimagesearch.com/2020/08/10/opencv-sudoku-solver-and-ocr/">OpenCV Sudoku Solver and OCR</a></p>
</li>
<li>
<p><a href="https://golsteyn.com/writing/sudoku">Using OpenCV to solve a sudoku</a></p>
</li>
<li>
<p><a href="https://docs.opencv.org/4.x/d1/dfb/intro.html">OpenCV Docs</a></p>
</li>
<li>
<p><a href="https://theailearner.com/tag/cv2-getperspectivetransform/">Understanding OpenCV getperspective transform</a></p>
</li>
<li>
<p><a href="https://www.ibm.com/cloud/learn/deep-learning">Deep Learning</a></p>
</li>
<li>
<p><a href="https://www.mathworks.com/discovery/deep-learning.html">What is Deep Learning?</a></p>
</li>
<li>
<p><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">A Comprehensive Guide to Convolutional Neural Networks</a></p>
</li>
<li>
<p><a href="https://www.simplilearn.com/tutorials/deep-learning-tutorial/convolutional-neural-network">Convolutional Neural Network Tutorial</a></p>
</li>
<li>
<p><a href="https://www.ibm.com/cloud/learn/convolutional-neural-networks">Convolutional Neural Networks</a></p>
</li>
<li>
<p><a href="https://www.udemy.com/course/python-for-computer-vision-with-opencv-and-deep-learning/">Python for Computer Vision with OpenCV and Deep Learning</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=tvP_FZ-D9Ng">Base Sudoku Solver</a></p>
</li>
<li>
<p><a href="https://www.geeksforgeeks.org/introduction-to-backtracking-data-structure-and-algorithm-tutorials/">Introduction to Backtracking - Data Structure and Algorithm Tutorials</a></p>
</li>
<li>
<p><a href="https://cs.lmu.edu/~ray/notes/backtracking/">Backtracking</a></p>
</li>
<li>
<p><a href="https://www.hackerearth.com/practice/basic-programming/recursion/recursion-and-backtracking/tutorial/">Recursion and Backtracking</a></p>
</li>
<li>
<p><a href="https://github.com/elehcimd/jupyter-opencv">Dockerfile setup reference</a></p>
</li>
<li>
<p><a href="https://code.visualstudio.com/remote/advancedcontainers/add-nonroot-user">Add non-root user in Dockerfile</a></p>
</li>
</ul>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": ".", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.top", "toc.integrate"], "search": "assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.220ee61c.min.js"></script>
      
    
  </body>
</html>